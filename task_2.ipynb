{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673ed538-b151-4e6a-86b3-da5bfff24394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce5a508d-2d3d-4239-b600-1dd77e576f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading CSV file containing labels\n",
    "labels_df = pd.read_csv(r'C:\\Users\\ethan\\Downloads\\alphabets_dataset\\alphabet_labels.csv')\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for index, row in labels_df.iterrows():\n",
    "    filename = row['file']\n",
    "    label = row['label']\n",
    "    img_path = os.path.join(r'C:\\Users\\ethan\\Downloads\\alphabets_dataset\\alphabet_images', filename)\n",
    "    img = load_img(img_path, color_mode='grayscale', target_size=(28, 28))\n",
    "    img_array = img_to_array(img)\n",
    "    images.append(img_array)\n",
    "    labels.append(label)\n",
    "\n",
    "images = np.array(images) / 255.0  # Normalizing pixel values between 0 and 1\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "# Encoding string labels to integers\n",
    "label_Encoder = LabelEncoder()\n",
    "labels = label_Encoder.fit_transform(labels)\n",
    "\n",
    "# Checking for class imbalances\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_weights = {i: 1.0 / count for i, count in enumerate(counts)}\n",
    "\n",
    "# Splitting data for training and testing \n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshaping data for the CNN input\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1155cc3-08f2-47b9-831c-a41525117323",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[1;32m---> 10\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m create_dataset(x_train, y_train)\n\u001b[0;32m     11\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m create_dataset(x_test, y_test, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating a TF dataset\n",
    "def create_dataset(images, labels, batch_size=32, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset(x_train, y_train)\n",
    "test_dataset = create_dataset(x_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e6c50aa-8161-4a12-a79b-8e2058544a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(labels))\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      5\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      6\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Building the model for character identification\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "# Learning rate scheduler\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                                 patience=3, min_lr=0.001)\n",
    "\n",
    "# Training the model with the dataset\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=20,\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[reduce_lr],\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196e51c5-494c-43fd-a1a9-b6e191ff2986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File C:\\Users\\ethan\\Downloads\\target_images\\target_images\\line_1.png exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Ensure the model is available as model\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_characters\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(all_characters)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# Map predictions to characters\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_character_from_prediction\u001b[39m(prediction):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verifying image paths\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading and preprocessing a test image\n",
    "def preprocess_test_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at path {img_path} could not be loaded.\")\n",
    "    return img\n",
    "\n",
    "# Slicing the test image into individual characters\n",
    "def slice_image_into_characters(img, char_width=28, char_height=28):\n",
    "    #L is a list of characters : 'X' if it identifies a letter and ' ' if it is just a whitespace\n",
    "    L=[]\n",
    "    characters = []\n",
    "    h, w = img.shape\n",
    "    last_x = 0\n",
    "    for y in range(0, h, char_height):\n",
    "        for x in range(0, w, char_width):\n",
    "            char = img[y:y + char_height, x:x + char_width]\n",
    "            if char.shape == (char_height, char_width):  # Ensure the character has the right dimensions\n",
    "                if np.mean(char) < 5:  # Assuming very low mean intensity indicates a space\n",
    "                    characters.append(' ')  # Represent space as a string ' '\n",
    "                else:\n",
    "                    char = char / 255.0  # Normalize pixel values\n",
    "                    char = char.reshape((char_height, char_width, 1))\n",
    "                    characters.append(char)\n",
    "                last_x = x\n",
    "    \n",
    "    #Identifying what is a character and what isnt\n",
    "    for char in characters:\n",
    "        if isinstance(char, str):\n",
    "            #print(char, end='')\n",
    "            L.append(char)\n",
    "        else:\n",
    "            #print('X', end='')  # Placeholder for non-string characters\n",
    "            L.append('X')\n",
    "    \n",
    "    return characters, L\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process test images and spaces\n",
    "all_characters_processed = []\n",
    "\n",
    "for path in test_image_paths:\n",
    "    try:\n",
    "        img = preprocess_test_image(path)\n",
    "        characters,L = slice_image_into_characters(img)\n",
    "        all_characters_processed.extend(characters)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "# Separate images and spaces\n",
    "images_to_predict = []\n",
    "for char in all_characters_processed:\n",
    "    if isinstance(char, np.ndarray):\n",
    "        images_to_predict.append(char)\n",
    "\n",
    "# Convert images to numpy array\n",
    "all_characters = np.array(images_to_predict)\n",
    "statement=''\n",
    "# Ensure the model is available as model\n",
    "if all_characters.shape[0] > 0:\n",
    "    # Make predictions\n",
    "    predictions = model.predict(all_characters)\n",
    "\n",
    "    # Map predictions to characters\n",
    "    def get_character_from_prediction(prediction):\n",
    "        classes = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz '  # Including space\n",
    "        return classes[np.argmax(prediction)]\n",
    "\n",
    "    predicted_characters = [get_character_from_prediction(pred) for pred in predictions]\n",
    "\n",
    "    # Print the predicted characters\n",
    "    \n",
    "    \n",
    "    printed_list=(''.join(predicted_characters))\n",
    "   #Compare our list of characters without spaces to list L which determines where the whitespaces go\n",
    "    index_L=index_pl=0\n",
    "    while index_L <(len(L)):\n",
    "       if L[index_L]==' ': \n",
    "           statement+=' '\n",
    "           index_L+=1\n",
    "       else: \n",
    "           statement+=printed_list[index_pl]\n",
    "           index_L+=1\n",
    "           index_pl+=1\n",
    "else:\n",
    "    print(\"No characters to predict.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2578fd2f-4e8f-48ef-b30a-acd351d7b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                line sentiment\n",
      "0  I AM REALLY FRUSTRATED BECAUSE YOU CONSTANTLY ...     Angry\n",
      "1  IT MAKES ME UPSET THAT YOU NEVER TAKE RESPONSI...     Angry\n",
      "2  I CANNOT BELIEVE YOU MISSED ANOTHER DEADLINE A...     Angry\n",
      "3  IT ANNOYS ME WHEN YOU INTERRUPT DURING MEETING...     Angry\n",
      "4  I AM TIRED OF YOUR EXCUSES EVERY TIME SOMETHIN...     Angry\n",
      "Class distribution before balancing: 0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 151s/step - accuracy: 0.2917 - loss: 1.0982 - val_accuracy: 0.5000 - val_loss: 1.0971\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.2500 - loss: 1.0987 - val_accuracy: 0.5000 - val_loss: 1.0960\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step - accuracy: 0.4583 - loss: 1.0914 - val_accuracy: 0.5000 - val_loss: 1.0945\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.5000 - loss: 1.0886 - val_accuracy: 0.5000 - val_loss: 1.0928\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829ms/step - accuracy: 0.4167 - loss: 1.0972 - val_accuracy: 0.6667 - val_loss: 1.0911\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.4167 - loss: 1.0898 - val_accuracy: 0.6667 - val_loss: 1.0892\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.4583 - loss: 1.0901 - val_accuracy: 0.6667 - val_loss: 1.0866\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.6667 - loss: 1.0706 - val_accuracy: 0.6667 - val_loss: 1.0835\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.5000 - loss: 1.0795 - val_accuracy: 0.6667 - val_loss: 1.0792\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.7083 - loss: 1.0703 - val_accuracy: 0.6667 - val_loss: 1.0737\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.7917 - loss: 1.0504 - val_accuracy: 0.6667 - val_loss: 1.0663\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.6667 - loss: 1.0528 - val_accuracy: 0.6667 - val_loss: 1.0572\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.7917 - loss: 1.0191 - val_accuracy: 0.6667 - val_loss: 1.0468\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6250 - loss: 1.0301 - val_accuracy: 0.6667 - val_loss: 1.0338\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.7917 - loss: 1.0078 - val_accuracy: 0.6667 - val_loss: 1.0179\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8750 - loss: 0.9569 - val_accuracy: 0.6667 - val_loss: 0.9976\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.8333 - loss: 0.9494 - val_accuracy: 0.6667 - val_loss: 0.9716\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.8333 - loss: 0.9120 - val_accuracy: 0.6667 - val_loss: 0.9392\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.7917 - loss: 0.9042 - val_accuracy: 0.6667 - val_loss: 0.8979\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.7917 - loss: 0.8365 - val_accuracy: 0.8333 - val_loss: 0.8531\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │         \u001b[38;5;34m320,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m66,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m41,216\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m195\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,294,859</span> (4.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,294,859\u001b[0m (4.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,619</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,619\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">863,240</span> (3.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m863,240\u001b[0m (3.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading data from CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\ethan\\Downloads\\sentiment_analysis_dataset.csv')\n",
    "\n",
    "\n",
    "sentences = df['line'].str.lower().tolist()\n",
    "labels = df['sentiment'].tolist()\n",
    "\n",
    "# Converting labels to numerical values\n",
    "label_dict = {'Angry': 0, 'Happy': 1, 'Neutral': 2}\n",
    "labels = [label_dict[label] for label in labels]\n",
    "\n",
    "# Ensuring class balance\n",
    "class_counts = pd.Series(labels).value_counts()\n",
    "print(\"Class distribution before balancing:\", class_counts)\n",
    "\n",
    "# Tokenizing sentences\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=50, padding='post', truncating='post')\n",
    "\n",
    "# Calculating class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Building the model for sentiment analysis\n",
    "model2 = tf.keras.Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=50),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compiling the model\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Training the model\n",
    "model2.fit(X_train, np.array(y_train), epochs=20, batch_size=32, validation_data=(X_val, np.array(y_val)), \n",
    "          class_weight=class_weights, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "48da3d5e-51c3-4b18-80eb-e2c984f6f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM REALLY ANNOYED BY YOUR CONSTANT COMPLAINTNG AND YOU NEVER OFFER ANY SOLUTIONS WHICH IS VERY UNHELPFUL AND NEGATIVE \n",
      "['i am really annoyed by your constant complaintng and you never offer any solutions which is very unhelpful and negative ']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "Angry\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Prediction\n",
    "\n",
    "test_sentences = [statement.lower()]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=50, padding='post', truncating='post')\n",
    "predictions = model2.predict(padded_test_sequences)\n",
    "\n",
    "sentiments = ['Angry', 'Happy', 'Neutral']\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(sentiments[np.argmax(prediction)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
